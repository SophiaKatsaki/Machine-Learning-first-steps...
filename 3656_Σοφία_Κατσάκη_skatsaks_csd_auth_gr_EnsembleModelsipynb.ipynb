{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8gU7AYPXMmA"
      },
      "source": [
        "## About iPython Notebooks ##\n",
        "\n",
        "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). \n",
        "\n",
        " **What you need to remember:**\n",
        "\n",
        "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
        "- Write code in the designated areas using Python 3 only\n",
        "- Do not modify the code outside of the designated areas\n",
        "- In some cases you will also need to explain the results. There will also be designated areas for that. \n",
        "\n",
        "Fill in your **NAME** and **AEM** below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO-jJrtNXMmH"
      },
      "outputs": [],
      "source": [
        "NAME = \"Sophia Katsaki\"\n",
        "AEM = \"3656\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh0EE7BJXMmJ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_VpnGyWXMmK"
      },
      "source": [
        "# Assignment 3 - Ensemble Methods #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dQ9XoGQXMmK"
      },
      "source": [
        "Welcome to your third assignment. This exercise will test your understanding on Ensemble Methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvHYIhS-XMmL"
      },
      "outputs": [],
      "source": [
        "# Always run this cell\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# USE THE FOLLOWING RANDOM STATE FOR YOUR CODE\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joKwpih2XMmM"
      },
      "source": [
        "## Download the Dataset ##\n",
        "Download the dataset using the following cell or from this [link](https://github.com/sakrifor/public/tree/master/machine_learning_course/EnsembleDataset) and put the files in the same folder as the .ipynb file. \n",
        "In this assignment you are going to work with a dataset originated from the [ImageCLEFmed: The Medical Task 2016](https://www.imageclef.org/2016/medical) and the **Compound figure detection** subtask. The goal of this subtask is to identify whether a figure is a compound figure (one image consists of more than one figure) or not. The train dataset consits of 4197 examples/figures and each figure has 4096 features which were extracted using a deep neural network. The *CLASS* column represents the class of each example where 1 is a compoung figure and 0 is not. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJdwPr0bXMmM",
        "outputId": "c7c7dfac-abc3-4787-c274-74cd40d6681a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('test_set_noclass.csv', <http.client.HTTPMessage at 0x7f1d3691cd10>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import urllib.request\n",
        "url_train = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/train_set.csv'\n",
        "filename_train = 'train_set.csv'\n",
        "urllib.request.urlretrieve(url_train, filename_train)\n",
        "url_test = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/test_set_noclass.csv'\n",
        "filename_test = 'test_set_noclass.csv'\n",
        "urllib.request.urlretrieve(url_test, filename_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0OVtYr7XMmN"
      },
      "outputs": [],
      "source": [
        "# Run this cell to load the data\n",
        "train_set = pd.read_csv(\"train_set.csv\").sample(frac=1).reset_index(drop=True)\n",
        "train_set.head()\n",
        "X = train_set.drop(columns=['CLASS'])\n",
        "y = train_set['CLASS'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxOGHSmqXMmO"
      },
      "source": [
        "## 1.0 Testing different ensemble methods ##\n",
        "In this part of the assignment you are asked to create and test different ensemble methods using the train_set.csv dataset. You should use **10-fold cross validation** for your tests and report the average f-measure weighted and balanced accuracy of your models. You can use [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) and select both metrics to be measured during the evaluation. Otherwise, you can use [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold).\n",
        "\n",
        "### !!! Use n_jobs=-1 where is posibble to use all the cores of a machine for running your tests ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww_u4OlrXMmO"
      },
      "source": [
        "### 1.1 Voting ###\n",
        "Create a voting classifier which uses three **simple** estimators/classifiers. Test both soft and hard voting and choose the best one. Consider as simple estimators the following:\n",
        "\n",
        "\n",
        "*   Decision Trees\n",
        "*   Linear Models\n",
        "*   Probabilistic Models (Naive Bayes)\n",
        "*   KNN Models  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwvPacgkXMmP"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#Three simple classifiers\n",
        "cls1 = DecisionTreeClassifier(random_state=RANDOM_STATE,max_depth=3) #Decision Tree Classifier with max depth = 3\n",
        "cls2 = LogisticRegression(random_state=RANDOM_STATE) # Logistic Regression Classifier\n",
        "cls3 = KNeighborsClassifier() # K-Nearest Neighbors Classifier\n",
        "\n",
        "#Soft and Hard Voting Classifiers\n",
        "soft_vcls = VotingClassifier(estimators = [('dt',cls1),('lr',cls2),('knn',cls3)], voting ='soft', n_jobs= 4) # Soft Voting Classifier\n",
        "hard_vcls = VotingClassifier(estimators = [('dt',cls1),('lr',cls2),('knn',cls3)], n_jobs= -1) # Hard Voting Classifier: the default voting is \"Hard Voting\"\n",
        "\n",
        "#Cross validation: The cross_val_score only calculates the results of cross validation and DOES NOT return a fitted model, but we dont need a fitted model at the particular moment.\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
        "svlcs_scores = [cross_val_score(soft_vcls, X, y, scoring='balanced_accuracy', cv=cv,n_jobs=-1), cross_val_score(soft_vcls, X, y, scoring='f1_weighted', cv=cv,n_jobs=-1)]\n",
        "hvlcs_scores = [cross_val_score(hard_vcls, X, y,scoring='balanced_accuracy' ,cv=cv, n_jobs=-1), cross_val_score(hard_vcls, X, y,scoring='f1_weighted',cv=cv,n_jobs =-1)]\n",
        "\n",
        "#F-measure weighted and Balanced Accuracy of Classifiers\n",
        "s_avg_fmeasure = svlcs_scores[1].mean() # The average f-measure weighted\n",
        "s_avg_accuracy = svlcs_scores[0].mean() # The average balanced accuracy\n",
        "h_avg_fmeasure = hvlcs_scores[1].mean() # The average f-measure weighted\n",
        "h_avg_accuracy = hvlcs_scores[0].mean() # The average accuracy\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQQvClrmXMmQ",
        "outputId": "af2161a9-63dc-42d6-9065-360084197c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier:\n",
            "VotingClassifier(estimators=[('dt',\n",
            "                              DecisionTreeClassifier(max_depth=3,\n",
            "                                                     random_state=42)),\n",
            "                             ('lr', LogisticRegression(random_state=42)),\n",
            "                             ('knn', KNeighborsClassifier())],\n",
            "                 n_jobs=4, voting='soft')\n",
            "F1 Weighted-Score: 0.8447 & Balanced Accuracy: 0.8369\n"
          ]
        }
      ],
      "source": [
        "print(\"Classifier:\")\n",
        "print(soft_vcls) \n",
        "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(s_avg_fmeasure,4), round(s_avg_accuracy,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-iJK9pFaDka"
      },
      "source": [
        "You should achive above 82% (Soft Voting Classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRNkVAvEYVbn",
        "outputId": "e2a0fa39-0622-466a-ad2c-0dd884155eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier:\n",
            "VotingClassifier(estimators=[('dt',\n",
            "                              DecisionTreeClassifier(max_depth=3,\n",
            "                                                     random_state=42)),\n",
            "                             ('lr', LogisticRegression(random_state=42)),\n",
            "                             ('knn', KNeighborsClassifier())],\n",
            "                 n_jobs=-1)\n",
            "F1 Weighted-Score: 0.825 & Balanced Accuracy: 0.8167\n"
          ]
        }
      ],
      "source": [
        "print(\"Classifier:\")\n",
        "print(hard_vcls)\n",
        "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(h_avg_fmeasure,4), round(h_avg_accuracy,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6M0CZO6aEHi"
      },
      "source": [
        "You should achieve above 80% in both! (Hard Voting Classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVPuIxwFXMmR"
      },
      "source": [
        "### 1.2 Stacking ###\n",
        "Create a stacking classifier which uses two more complex estimators. Try different simple classifiers (like the ones mentioned before) for the combination of the initial estimators. Report your results in the following cell.\n",
        "\n",
        "Consider as complex estimators the following:\n",
        "\n",
        "*   Random Forest\n",
        "*   SVM\n",
        "*   Gradient Boosting\n",
        "*   MLP\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HX6T1qrFXMmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "002823f0-6237-42ec-f365-e47be4d8aa3d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        }
      ],
      "source": [
        "# BEGIN CODE HERE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#Three complex estimators\n",
        "cls1 = RandomForestClassifier(max_depth=5,n_jobs=-1,random_state = RANDOM_STATE) # Random Forest Classifier with the default n=100 estimators\n",
        "#cls2 = GradientBoostingClassifier(n_estimators=50,max_depth=1,random_state = RANDOM_STATE) # Gradient Boosting Classifier\n",
        "cls2 = SVC(random_state = RANDOM_STATE) #C-Support Vector Classification\n",
        "cls3 =  MLPClassifier(random_state=RANDOM_STATE) #Multi-Layer Perceptron Classifier\n",
        "\n",
        "#Stacking Classifier\n",
        "s_est = LogisticRegression(random_state=RANDOM_STATE,n_jobs=-1)\n",
        "cls = [('rf',cls1),('svm',cls2),('mlp',cls3)] #the two simple estimators\n",
        "scls = StackingClassifier(cls,s_est) \n",
        "\n",
        "#Cross Validation\n",
        "cv_s = KFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
        "scores = [cross_val_score(scls, X, y, scoring='balanced_accuracy', cv=cv_s,n_jobs=-1), cross_val_score(scls, X, y, scoring='f1_weighted', cv=cv_s,n_jobs=-1)]\n",
        "avg_fmeasure = scores[1].mean() # The average f-measure weighted\n",
        "avg_accuracy = scores[0].mean() # The average balanced accuracy \n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JLRzkQ1XMmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41c2d89-988b-49a6-d8da-a4b0318b3c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier:\n",
            "StackingClassifier(estimators=[('rf',\n",
            "                                RandomForestClassifier(max_depth=5, n_jobs=-1,\n",
            "                                                       random_state=42)),\n",
            "                               ('svm', SVC(random_state=42)),\n",
            "                               ('mlp', MLPClassifier(random_state=42))],\n",
            "                   final_estimator=LogisticRegression(n_jobs=-1,\n",
            "                                                      random_state=42))\n",
            "F1 Weighted Score: 0.8617 & Balanced Accuracy: 0.8557\n"
          ]
        }
      ],
      "source": [
        "print(\"Classifier:\")\n",
        "print(scls)\n",
        "print(\"F1 Weighted Score: {} & Balanced Accuracy: {}\".format(round(avg_fmeasure,4), round(avg_accuracy,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcgOx-HPvBI-"
      },
      "source": [
        "You should achieve above 85% in both"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-nqW51xXMmU"
      },
      "source": [
        "## 2.0 Randomization ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPG8MdFLXMmV"
      },
      "source": [
        "**2.1** You are asked to create three ensembles of decision trees where each one uses a different method for producing homogeneous ensembles. Compare them with a simple decision tree classifier and report your results in the dictionaries (dict) below using as key the given name of your classifier and as value the f1_weighted/balanced_accuracy score. The dictionaries should contain four different elements.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmkaP-DjXMmV"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#Simple DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
        "\n",
        "#Random Subspace\n",
        "ens1 = BaggingClassifier(random_state=RANDOM_STATE,max_features=0.65) #The base estimator is the default DecisionTreeClassifier. Each estimator can access 65% of the features of the dataset.\n",
        "\n",
        "#Random Patches\n",
        "ens2 = BaggingClassifier(random_state=RANDOM_STATE, max_features=0.65, max_samples=0.65) #Each estimator can access 65% of the samples and 65% of the features of the set.\n",
        "\n",
        "#Simple Bagging\n",
        "ens3 = BaggingClassifier(random_state=RANDOM_STATE)\n",
        "\n",
        "#10-Fold Cross Validation\n",
        "cv= KFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "#Four lists with the balanced_accuracy and f1_weighted scores. One list for every Classifier.\n",
        "tree_scores = [cross_val_score(tree, X, y, scoring='balanced_accuracy', cv=cv,n_jobs=-1), cross_val_score(tree, X, y, scoring='f1_weighted', cv=cv,n_jobs=-1)]\n",
        "rs_scores = [cross_val_score(ens1, X, y, scoring='balanced_accuracy', cv=cv,n_jobs=-1), cross_val_score(ens1, X, y, scoring='f1_weighted', cv=cv,n_jobs=-1)]\n",
        "rp_scores = [cross_val_score(ens2, X, y, scoring='balanced_accuracy', cv=cv,n_jobs=-1), cross_val_score(ens2, X, y, scoring='f1_weighted', cv=cv,n_jobs=-1)]\n",
        "b_scores = [cross_val_score(ens3, X, y, scoring='balanced_accuracy', cv=cv,n_jobs=-1), cross_val_score(ens3, X, y, scoring='f1_weighted', cv=cv,n_jobs=-1)]\n",
        "\n",
        "#f_weighted and balanced accuracy dictionaries\n",
        "f_measures = dict()\n",
        "accuracies = dict()\n",
        "\n",
        "f_measures['Simple Decision Tree'] = tree_scores[1].mean() #The average f1_weighted score for the simple DecisionTreeClassifier\n",
        "accuracies['Simple Decision Tree'] = tree_scores[0].mean() #The average balanced_accuracy for the simple DecisionTreeClassifier\n",
        "\n",
        "f_measures['Random subspace'] = rs_scores[1].mean() #The average f1_weighted score for the Random subspace ensemble\n",
        "accuracies['Random subspace'] = rs_scores[0].mean() #The average balanced_accuracy score for the Random subspace ensemble\n",
        "\n",
        "f_measures['Random Patches'] = rp_scores[1].mean() #The average f1_weighted score for the Random Patches ensemble\n",
        "accuracies['Random Patches'] = rp_scores[0].mean() #The average f1_weighted score for the Random Patches ensemble\n",
        "\n",
        "f_measures['Bagging'] = b_scores[1].mean() #The average f1_weighted score for the Bagging ensemble\n",
        "accuracies['Bagging'] = b_scores[0].mean() #The average f1_weighted score for the Bagging ensemble\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUqhDUuCXMmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725e93bf-b9e8-4434-cc9c-713dec7a4099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaggingClassifier(max_features=0.65, random_state=42)\n",
            "BaggingClassifier(max_features=0.65, max_samples=0.65, random_state=42)\n",
            "BaggingClassifier(random_state=42)\n",
            "DecisionTreeClassifier(random_state=42)\n",
            "Classifier:Simple Decision Tree -  F1 Weighted:0.704\n",
            "Classifier:Random subspace -  F1 Weighted:0.7676\n",
            "Classifier:Random Patches -  F1 Weighted:0.7767\n",
            "Classifier:Bagging -  F1 Weighted:0.7789\n",
            "Classifier:Simple Decision Tree -  BalancedAccuracy:0.695\n",
            "Classifier:Random subspace -  BalancedAccuracy:0.7628\n",
            "Classifier:Random Patches -  BalancedAccuracy:0.7718\n",
            "Classifier:Bagging -  BalancedAccuracy:0.7732\n"
          ]
        }
      ],
      "source": [
        "print(ens1)\n",
        "print(ens2)\n",
        "print(ens3)\n",
        "print(tree)\n",
        "for name,score in f_measures.items():\n",
        "    print(\"Classifier:{} -  F1 Weighted:{}\".format(name,round(score,4)))\n",
        "for name,score in accuracies.items():\n",
        "    print(\"Classifier:{} -  BalancedAccuracy:{}\".format(name,round(score,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqdXTE_2XMmX"
      },
      "source": [
        "**2.2** Describe your classifiers and your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU9POFftXMmX"
      },
      "source": [
        "###Classifiers\n",
        "The first classifier that was used was a simple DecisionTreeClassifier which \n",
        "nodes are expanded without a limit in maximum depth. The second one is a Bagging Classifier, which uses the default base estimtator (the DecisionTreeClassifier). The max_features parameter is set to 0.65, which means that each base estimator can access 65% of the features of the dataset. In this way, we can use the Random Subspaces technique, in which we only select random features of the dataset each time for each estimator. The third one, is also a Bagging Classifier, but not only does it have the max_features parameter set to 0.65, but also the max_samples parameter is set to 0.65. That means that 65% of the samples and 65% of the features are used for each estimator.Each time,we select random patches of the data.The fourth estimator is a simple Bagging Classifier.  \n",
        "\n",
        "###Results \n",
        "After performing 10-fold Cross Validation, we can see that the f1_weighted scores and the balanced_accuracy scores of the Bagging Classifiers are higher than the scores of the simple DecisionTreeClassifier.The results can be seen in 2.1 with detail. In general, bagging, reduces variance. So, the accuracy in such estimators is expected to be higher. In this example, we can see that bagging improves the results of a single model. Basically, we use different combinations and parts of the original data each time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkJeuV1FXMmX"
      },
      "source": [
        "**2.3** Increasing the number of estimators in a bagging classifier can drastically increase the training time of a classifier. Is there any solution to this problem? Can the same solution be applied to boosting classifiers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApNEPcWEXMmY"
      },
      "source": [
        "If we use the parameter n_jobs in our bagging classifier, we can solve this problem. The n_jobs parameter is setting the number of jobs to run in parallel for fitting as well as predicting. For even better results, we can set n_jobs to -1, which means that all the processors will be used for this task at the same time. Unfortunately, we cannot use the same parameter in boosting classifiers, due to the fact that they cannot produce their results at the same time. The models are trained sequentally (one after the other) and each model tries to correct the mistakes of the previous one that was trained. Due to the fact that each model depends on the previous ones, they cannot be trained in parallel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgvsCbUGXMmY"
      },
      "source": [
        "## 3.0 Creating the best classifier ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6daX2mRXMmZ"
      },
      "source": [
        "**3.1** In this part of the assignment you are asked to train the best possible ensemble! Describe the process you followed to achieve this result. How did you choose your classifier and your parameters and why. Report the f-measure (weighted) & balanced accuracy (10-fold cross validation) of your final classifier and results of classifiers you tried in the cell following the code. Can you achieve a balanced accuracy over 83-84%?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00xAQ0HfXMmZ"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "from sklearn.ensemble import VotingClassifier,RandomForestClassifier,GradientBoostingClassifier,StackingClassifier,AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold,cross_val_score\n",
        "from sklearn import svm\n",
        "\n",
        "#Three complex estimators\n",
        "#cls1 = RandomForestClassifier(max_depth=1,n_jobs=-1,random_state = RANDOM_STATE) # Random Forest Classifier with the default n=100 estimators\n",
        "#cls2 = SVC(random_state = RANDOM_STATE) #C-Support Vector Classification\n",
        "#cls3 =  MLPClassifier(random_state=RANDOM_STATE) #Multi-Layer Perceptron Classifier\n",
        "#adb = AdaBoostClassifier(cls1,n_estimators=1000,random_state=RANDOM_STATE)\n",
        "\n",
        "#Stacking Classifier\n",
        "#s_est = LogisticRegression(random_state=RANDOM_STATE,n_jobs=-1)\n",
        "#cls = [('rf',cls1),('svm',cls2),('mlp',cls3)] #the two simple estimators\n",
        "best_cls = scls\n",
        "\n",
        "#Cross Validation\n",
        "#cv_s = KFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
        "#scores = [cross_val_score(best_cls, X, y, scoring='balanced_accuracy', cv=cv_s,n_jobs=-1), cross_val_score(best_cls, X, y, scoring='f1_weighted', cv=cv_s,n_jobs=-1)]\n",
        "best_fmeasure = scores[1].mean() # The average f-measure weighted\n",
        "best_accuracy = scores[0].mean() # The average balanced accuracy \n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbLB09agXMma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6147147-233b-4e78-9fa9-1164274a1302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier:\n",
            "F1 Weighted-Score:0.8616744215730234 & Balanced Accuracy:0.8557083558436347\n"
          ]
        }
      ],
      "source": [
        "print(\"Classifier:\")\n",
        "#print(best_cls)  \n",
        "print(\"F1 Weighted-Score:{} & Balanced Accuracy:{}\".format(best_fmeasure, best_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnos1uqzXMma"
      },
      "source": [
        "**3.2** Describe the process you followed to achieve this result. How did you choose your classifier and your parameters and why. Report the f-measure & accuracy (10-fold cross validation) of your final classifier and results of classifiers you tried in the cell following the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5dAfbTfXMmb"
      },
      "source": [
        "We need a strong and complex final estimator, even if takes some time to run. Here, the thought was to create a complex model, but without big grid searches for finding the best parameters. The stacking estimator was created with a RandomForestClassifier, a SVC, and an MLPClassifier. The meta-estimator was Logistic Regression. In the whole process of choosing the best estimator, the focus was on the choice and combinations of models, and not on choosing the best parameters. We can find the 'optimal' parameters with the help of grid searches. \n",
        "- The scores of the final stacking estimator are:\n",
        "F1 Weighted Score: 0.8617 & Balanced Accuracy: 0.8557\n",
        "\n",
        "The scores of other models were the following:\n",
        "- The stacking classifer that we can see in 3.1, was combined with the voting classifier from 1.1(as they were the best estimators so far). The final estimator combined those two also with stacking. The run time was VERY high. The results are: \n",
        " F1 Weighted-Score:0.8593 & Balanced Accuracy:0.8529\n",
        "\n",
        "- The stacking classifier described above was combined with the adaboost boosting technique, with a voting classifier but the results were around 75% for both metrics.\n",
        "\n",
        "- The stacking classifier of complex models was combined with the voting classifier of simple models from 1.1. The final estimator was again a voting classifier that combined those two. But the results were not so satisfying as the stacking classifier on its own:\n",
        "F1 Weighted-Score:0.8463 & Balanced Accuracy:0.8460\n",
        "\n",
        "- The adaboost boosting algorithm had a random forest algorithm as its base estimator. The results could have been higher:\n",
        "F1 Weighted-Score:0.8437 & Balanced Accuracy:0.8359\n",
        "\n",
        "- The adaboost boosting algotithm had a gradient boosting as its base (to see if it is possible to combine two boosting classifiers in that way). The time that it took to run was very long, so it is probably not a very bright idea.\n",
        "\n",
        "- The usual stacking classifier with the complex models, was combined with an adaboost classifier that had as its base the random forest, through a voting classifier. The results were:\n",
        "F1 Weighted-Score:0.8498 & Balanced Accuracy:0.8483\n",
        "\n",
        "In general, we can combine a lot of simple and complex models and techniques together to find the best ensemble.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQEFCmbcXMmb"
      },
      "source": [
        "**3.3** Create a classifier that is going to be used in production - in a live system. Use the *test_set_noclass.csv* to make predictions. Store the predictions in a list.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQPgm_ubXMmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f838341-10cc-4491-a471-e2445dc3d791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Weighted-Score:0.8616744215730234 & Balanced Accuracy:0.8557083558436347\n",
            "[1 1 1 ... 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "# BEGIN CODE HERE\n",
        "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,GradientBoostingClassifier,StackingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import urllib.request\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#Creating the test set\n",
        "url_test = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/test_set_noclass.csv'\n",
        "filename_test = 'test_set_noclass.csv'\n",
        "urllib.request.urlretrieve(url_test, filename_test)\n",
        "test_set = pd.read_csv(\"test_set_noclass.csv\")\n",
        "\n",
        "#Three complex estimators\n",
        "#cls1 = RandomForestClassifier(max_depth=1,n_jobs=-1,random_state = RANDOM_STATE) # Random Forest Classifier with the default n=100 estimators\n",
        "#cls2 = GradientBoostingClassifier(n_estimators=50,max_depth=1,random_state = RANDOM_STATE) # Gradient Boosting Classifier\n",
        "#cls2 = SVC(random_state = RANDOM_STATE)\n",
        "#cls3 =  MLPClassifier(random_state=RANDOM_STATE) #Multi-Layer Perceptron Classifier\n",
        "\n",
        "#Stacking Classifier\n",
        "#s_est = LogisticRegression(random_state=RANDOM_STATE,n_jobs=-1)\n",
        "#cls = [('rf',cls1),('svm',cls2),('mlp',cls3)] #the two simple estimators\n",
        "predictionsclassifier = scls\n",
        "\n",
        "#10-Fold Cross Validation\n",
        "#cv= KFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
        "#scores = [cross_val_score(predictionsclassifier, X, y, scoring='balanced_accuracy', cv=cv,n_jobs=-1), cross_val_score(predictionsclassifier, X, y, scoring='f1_weighted', cv=cv,n_jobs=-1)]\n",
        "predictionsclassifier.fit(X,y)\n",
        "fmeasureb = scores[1].mean() # The average f-measure weighted\n",
        "accuracyb = scores[0].mean() # The average balanced accuracy \n",
        "predictions = predictionsclassifier.predict(test_set)\n",
        "print(\"F1 Weighted-Score:{} & Balanced Accuracy:{}\".format(fmeasureb, accuracyb))\n",
        "print(predictions)\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnAp-d2DXMmf"
      },
      "source": [
        "The main idea of building this classifier is to avoid overifitting,as we are going to make predictions for the test set. We want the predictions to be as accurate as they can be. So, ensemble methods are a wise choice, as they reduce variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Neagvu0TXMmg"
      },
      "source": [
        "#### This following cell will not be executed. The test_set.csv with the classes will be made available after the deadline and this cell is for testing purposes!!! Do not modify it! ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7K7iI7BXMmg"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "  from sklearn.metrics import f1_score, balanced_accuracy_score\n",
        "  final_test_set = pd.read_csv('test_set.csv')\n",
        "  ground_truth = final_test_set['CLASS']\n",
        "  print(\"Balanced Accuracy: {}\".format(balanced_accuracy_score(predictions, ground_truth)))\n",
        "  print(\"F1 Weighted-Score: {}\".format(f1_score(predictions, ground_truth, average='weighted')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJH-9KdOzW7z"
      },
      "source": [
        "Both should aim above 85%!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}