{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDrcOVDGnyDI"
      },
      "source": [
        "## About iPython Notebooks ##\n",
        "\n",
        "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). \n",
        "\n",
        " **What you need to remember:**\n",
        "\n",
        "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
        "- Write code in the designated areas using Python 3 only\n",
        "- Do not modify the code outside of the designated areas\n",
        "- In some cases you will also need to explain the results. There will also be designated areas for that. \n",
        "\n",
        "Fill in your **NAME** and **AEM** below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JEJWwHpJnyDK"
      },
      "outputs": [],
      "source": [
        "NAME = \"Σοφία Κατσάκη\"\n",
        "AEM = \"3656\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgauGbInyDM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_FF68cfznyDO",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ce63642cafb413e7903d83d2f2cd3637",
          "grade": false,
          "grade_id": "cell-f62db6dce1ed3f2e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Assignment 2 - Decision Trees #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zq29ctnanyDO",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "29d61ce286fdb8fd61c7f8e89a9e1339",
          "grade": false,
          "grade_id": "cell-dce2e73cee9a5017",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Welcome to your second assignment. This exercise gives you an introduction to [scikit-learn](https://scikit-learn.org/stable/). A simple but efficient machine learning library in Python. It also gives you a wide understanding on how decision trees work. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mb4Wf4IdnyDP",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "50a108d2f1e1a1ee2fde80743c0543fe",
          "grade": false,
          "grade_id": "cell-83ca2b0456fb85db",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "After this assignment you will:\n",
        "- Be able to use the scikit-learn library and train your own model from scratch.\n",
        "- Be able to train and understand decision trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "sLqpxgvbnyDQ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "396c39a0797964c378ebb90cf18a29de",
          "grade": false,
          "grade_id": "cell-2cef6d48eea484d8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Always run this cell\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "\n",
        "# USE THIS RANDOM VARIABLE TO PRODUCE THE SAME RESULTS\n",
        "RANDOM_VARIABLE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLqRTrLTnyDR"
      },
      "source": [
        "## 1. Scikit-Learn and Decision Trees ##\n",
        "\n",
        "You are going to use the scikit-learn library to train a model for detecting breast cancer using the [Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) (+ [Additional information](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset)) by training a model using [decision trees](https://scikit-learn.org/stable/modules/tree.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7d5K-BdnyDS"
      },
      "source": [
        "**1.1** Load the breast cancer dataset using the scikit learn library and split the dataset into train and test set using the appropriate function. Use 33% of the dataset as the test set. Define as X the attributes and as y the target values. Do not forget to set the random_state parameter as the *RANDOM_VARIABLE* defined above. Use this variable for all the random_state parameters in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "id": "NfF54h6anyDS",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4b873328ea05f6ef9c08827168c7b835",
          "grade": false,
          "grade_id": "cell-1f0c2f3918333cf6",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "X, y = load_breast_cancer().data,load_breast_cancer().target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=RANDOM_VARIABLE)\n",
        "\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "FiOtzHkpnyDT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3603b2ba8916ffdad9e9c53f31546b4c",
          "grade": true,
          "grade_id": "cell-3f43c895ceaf57a9",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ea45db-81f0-4060-b9d7-d9475eec4242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train set:381\n",
            "Size of test set:188\n",
            "Unique classes:2\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of train set:{}\".format(len(y_train)))\n",
        "print(\"Size of test set:{}\".format(len(y_test)))\n",
        "print(\"Unique classes:{}\".format(len(set(y_test))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "JuW_lKVFnyDU",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "62285a7bd3ab59718b89f7e09de0fea4",
          "grade": false,
          "grade_id": "cell-1ce621a108e76a15",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "\n",
        "```\n",
        "Size of train set:381  \n",
        "Size of test set:188  \n",
        "Unique classes:2\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUB8sl0NnyDV"
      },
      "source": [
        "**1.2** Train two DecisionTree classifiers and report the F1 score. Use the information gain for the one classifier and the Gini impurity for the other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "id": "nPQFaOhLnyDW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "17197b62614427a979fcbab7ed2734dd",
          "grade": false,
          "grade_id": "cell-a7fa1d29509eb2a1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "classifier_gini = DecisionTreeClassifier(random_state = RANDOM_VARIABLE) #the 'gini' criterion is the default one\n",
        "classifier_igain = DecisionTreeClassifier(criterion='entropy',random_state = RANDOM_VARIABLE)\n",
        "\n",
        "classifier_gini.fit(X_train,y_train)\n",
        "classifier_igain.fit(X_train,y_train)\n",
        "\n",
        "#predictions\n",
        "prediction_gini = classifier_gini.predict(X_test)\n",
        "prediction_igain = classifier_igain.predict(X_test)\n",
        "\n",
        "#f_scores \n",
        "f_measure_gini = f1_score(y_test,prediction_gini)\n",
        "f_measure_igain = f1_score(y_test,prediction_igain)\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "qToIpGtnnyDX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6d9aab4355c27c346f7e6548f233e758",
          "grade": true,
          "grade_id": "cell-09657a82bf4028c4",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "752d033a-eae0-4365-e1de-12c010ccf75e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Measure Gini: 0.9372384937238494\n",
            "F-Measure Information Gain: 0.9596774193548386\n"
          ]
        }
      ],
      "source": [
        "print(\"F-Measure Gini: {}\".format(f_measure_gini))\n",
        "print(\"F-Measure Information Gain: {}\".format(f_measure_igain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "hn9nblQ5nyDY",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f3facbbef0dd8f25ad12bfec7c174818",
          "grade": false,
          "grade_id": "cell-b0d8630f3b764cf3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "\n",
        "```\n",
        "F-Measure Gini: 0.9372384937238494\n",
        "F-Measure Information Gain: 0.9596774193548386\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "31Iyi9SJnyDZ",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f2532168d16e8c9bffba3d7d8e1efce7",
          "grade": false,
          "grade_id": "cell-591ba122016b6db5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**1.3** Find the maximum depth reached by the tree that used the Gini impurity. Train multiple classifiers by modifying the max_depth within the range from 1 to maximum depth and save the f1 scores to the corresponding list of the *fscores* dictionary (one list for training set and one for test set). Before appending the scores to the corresponding list, multiply them by 100, and round the values to 2 decimals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "id": "U7gSfRu_nyDa",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "54cf257e90a3cb5877db81297bedd45c",
          "grade": false,
          "grade_id": "cell-31c58b6161a3907d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "depth = classifier_gini.tree_.max_depth\n",
        "fscores = {}\n",
        "fscores['train'] = []\n",
        "fscores['test'] = []\n",
        "\n",
        "for i in range(1,depth+1,1):\n",
        "    classifier_gini = DecisionTreeClassifier(max_depth = i,random_state = RANDOM_VARIABLE)\n",
        "    classifier_gini.fit(X_train,y_train)\n",
        "\n",
        "    #Train set f1_score\n",
        "    prediction_gini = classifier_gini.predict(X_train)\n",
        "    f_measure_gini = round(100*f1_score(y_train,prediction_gini),2)\n",
        "    fscores['train'].append(f_measure_gini)\n",
        "\n",
        "    #Test set f1_score\n",
        "    prediction_gini = classifier_gini.predict(X_test)\n",
        "    f_measure_gini = round(100*f1_score(y_test,prediction_gini),2)\n",
        "    fscores['test'].append(f_measure_gini)\n",
        "  \n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "2395Por-nyDa",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "70a249937f2f690c6ce855debaed204c",
          "grade": true,
          "grade_id": "cell-0c300109423f53b9",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "90b7c00b-f07c-4180-ff2e-65037900006b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
            "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n"
          ]
        }
      ],
      "source": [
        "print(\"Fscores Train: {}\".format(fscores['train']))\n",
        "print(\"Fscores Test:  {}\".format(fscores['test']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f37yzYcbnyDb",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3db472d2b9db7a42cc012cd96fdeb499",
          "grade": false,
          "grade_id": "cell-75789627f20d2c94",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "```\n",
        "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
        "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4stz0V9knyDd",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bca7d4c160c767d27a09b4620d27d56e",
          "grade": false,
          "grade_id": "cell-5906e6d5efa70282",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**1.4** Compare the results from the train set with the results from the test set. What do you notice? How are you going to choose the max_depth of your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "kwtDaX3JnyDe",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "424ac10e4e22ca9e32207deee3bf0f57",
          "grade": true,
          "grade_id": "cell-c9c6ea0e40d98b83",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "First of all, the f1 score metric is the weighted average of recall and precision and takes false positives and false negatives into account.Comparing the results from the train set with the results from the test set, we notice that the model reaches very high f1-scores, when it comes to the train data. It even reaches a 100% score, when the depth is equal to 7. The model learns the training data so well and that even results in the model learning the noise in the train set. The score of the model in the test set is also improving, but not as much as the train set, as the test set is an unseen data set and the model cannot fully adapt to the noise etc. The improvement in the test set can be seen until the moment the max_depth is equal to 3(but we also notice that there is a small increase in the f-score from depth 4 to 5), and then it is starting to decrease. So, the ideal max_depth for the tree is going to be 3, as it is the \"peak point\", for the f1-score of the test set, but in such cases we can also use grid search to find the ideal parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "PIw1fVFenyDe",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "217666fcc2e383d6f2c1904c9d6a71be",
          "grade": false,
          "grade_id": "cell-9ef42e6c90ea2ffe",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2.0 Pipelines ##\n",
        "\n",
        "**2.1** In this part of the exercise you are going to build a pipeline from scratch for a classification problem. Load the **income.csv** file and train a DecisionTree model that will predict the *income* variable. This dataset is a modification of the original Adult Income dataset found [here](http://archive.ics.uci.edu/ml/datasets/Adult). Report the f1-score and accuracy score of the test set found in **income_test.csv**. Your pipeline should be able to handle missing values and categorical features (scikit-learn's decision trees do not handle categorical values). You can preprocess the dataset as you like in order to achieve higher scores.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7jJW-avitO9E"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "#train set includes all columns except from the 'income' column and the education column \n",
        "train_set = pd.read_csv('income.csv', usecols = [i for i in range(13)]) #columns from 0 to 12\n",
        "train_set = train_set.drop(['education'],axis=1)\n",
        "\n",
        "#y train includes only the 'income' column\n",
        "y_train = pd.read_csv('income.csv',usecols=['income'])\n",
        "y_train['income'] = y_train['income'].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "\n",
        "#test set includes all columns except from the 'income' column and the education column\n",
        "test_set = pd.read_csv('income_test.csv', usecols = [i for i in range(13)]) #columns from 'age' to hours-per-week'\n",
        "test_set = test_set.drop(['education'],axis=1)\n",
        "\n",
        "#y test includes only the 'income' column\n",
        "y_test = pd.read_csv('income_test.csv',usecols=['income'])\n",
        "y_test['income'] = y_test['income'].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "# End CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akVGpGHDuav4"
      },
      "source": [
        "**2.2** Create and test your pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pv6z98huuZ6M"
      },
      "outputs": [],
      "source": [
        "#Simple Imputer strategy for numerical values\n",
        "numeric_features = ['age','fnlwgt','education_num','capital-gain','capital-loss','hours-per-week']\n",
        "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean'))])\n",
        "\n",
        "#The categorical features 'workclass' and 'occupation' have some missing values. We will ignore the NaN values, that are going to be all\n",
        "#zeros after we use the OneHotEncoder \n",
        "categorical_features = ['workclass','marital-status','occupation','relationship','race','sex']\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[('numeric',numeric_transformer,numeric_features),\n",
        "                                               ('one_hot', categorical_transformer, categorical_features)])\n",
        "\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', DecisionTreeClassifier(random_state=RANDOM_VARIABLE))]) #gini is the default criterion\n",
        "clf.fit(train_set,y_train)\n",
        "y_predict = clf.predict(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3uaArYmQvKcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b52c627-5afd-4f32-b5e8-4cd239f93783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score Accuracy: 0.807\n",
            "Model score F1 Weighted: 0.808\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test, y_predict))\n",
        "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test, y_predict,average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz_MWnYY2r3-"
      },
      "source": [
        "**2.3** Perform a gooood grid search to find the best parameters for your pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "id": "RNECyUFtnyDf",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "152ab2dd6861b198b879a78ebadc4ee4",
          "grade": true,
          "grade_id": "cell-dd950ab2eb40d8a4",
          "locked": false,
          "points": 45,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "e85c4bee-f6c7-4d0d-be4d-eac2e0171a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params:\n",
            "{'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_features': 0.75, 'classifier__min_samples_leaf': 30, 'preprocessor__numeric__imputer__strategy': 'mean'}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    \"preprocessor__numeric__imputer__strategy\": [\"mean\", \"median\",\"most_frequent\"],\n",
        "    \"classifier__max_depth\": [2, 5, 7, 10, 13],\n",
        "    \"classifier__criterion\": [\"gini\",\"entropy\"],\n",
        "    \"classifier__max_features\": [0.25, 0.5, 0.75, None],\n",
        "    \"classifier__min_samples_leaf\": [1,10,20,30,40,50],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
        "grid_search.fit(train_set, y_train)\n",
        "y_predict =  grid_search.predict(test_set)\n",
        "\n",
        "print(\"Best params:\")\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OhE0haFuw57D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d8e67ea-f3d2-462a-ece0-c2b94f235464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score Accuracy: 0.851\n",
            "Model score F1 Weighted: 0.841\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test,y_predict))\n",
        "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test,y_predict,average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f_lIQ1-wnyDg",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ee9d4c2635307395bdef2efb941106ae",
          "grade": false,
          "grade_id": "cell-2c3327274958bbad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**2.4** Describe the process you followed to achieve the results above. Your description should include, but is not limited to the following \n",
        "- How do you handle missing values and why\n",
        "- How do you handle categorical variables and why\n",
        "- Any further preprocessing steps\n",
        "- How do you evaluate your model and how did you choose its parameters \n",
        "- Report any additional results and comments on your approach.\n",
        "\n",
        "You should achieve at least 85% accuracy score and 84% f1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "76FF0gYVnyDh",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1aaf3ddda45b52c2e43089b082d030f1",
          "grade": true,
          "grade_id": "cell-80274fd09b80518c",
          "locked": false,
          "points": 20,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "- Missing values in numerical features were replaced with the mean of all values. Here, we can see that the data set happened to have no NaN numerical values. The code that is handling missing values is still included though, as it appies to most cases(the majority of data sets are expected to have some missing values). In order to achieve this, we use SimpleImputer. We do not drop the examples with missing values, as the number of examples available will be decreased(there are not so many examples with missing values, though).The mean of all values is a good estimator of the values missing, because it takes into account all the other values and is not extremely high or low.\n",
        "\n",
        "- Categorical values need to be converted in order for the accuracy and the f1_score of the model to be higher. The different words of each categorical variable needs to be destinguished. This can be accomplished through the use of OneHotEncoder. The missing values in categorical variables, are \"ignored\" and therefore instead of 0's and 1's, we are going to have only 0's in the variable that is missing.\n",
        "\n",
        "- For the train_set and test_set we use every column, except from the one that we want to predict, the 'income' column. This column is included in both y_train and y_test sets. Additionaly, in train_set and test_set we drop the column 'education', as the column 'education_num' describes its content well and it is numerical. We may need to drop other columns as well, such as 'marital_status' or 'race' that seem kind of irrelevant to the income, but here we do not proceed to try different column combinations. Also, in y_train and y_test data, the\n",
        "\"<=50K\" and \">50K\" values, were mapped to 0's and 1's, in order for them to become numerical and therefore easier to handle.\n",
        "\n",
        "- In 2.2, a simple Pipeline was used. The data were fitted and a simple prediction was made. The SimpleImputer and OneHotEncoder were used, with the strategies described above. In 2.3, the default 5-fold cross-validation (4 parts for training and 1 for testing,each time) is used. When it comes to the parameters, for the imputer strategy for numerical values, the \"mean\",\"median\" and \"most_frequent\" were tried. For the max_depth different values from 2 to 10 were tried. For the criterion of finding the best way to deal with impurity, the \"gini\" and the \"entropy\" were tried. For the max features the values tried were: 0.25, 0.5, 0.75, and None and finally for the min samples in a single leaf the values tried were:1,10,20,30,40,50. In each case, different values of each parameter were tried, in order to have a variety of choices for the best parameters.\n",
        "  \n",
        "\n",
        "- The best result was when using: 'gini' as a criterion, 10 as max_depth, the 0.75 float value as max_features, 30 as minimum samples in a leaf and 'mean' as the numeric imputer strategy.The results have the expected accuracy(around 85% accuracy for the simple score and 84% for the f1 score), but we can always try different parameters, different combinations of columns that are involved etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mNqPY_yanyDj",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8cef3f333ab449ed91b81ea96695e712",
          "grade": false,
          "grade_id": "cell-555d20216f9bbec2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 3.0 Common Issues ## "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USyDSnDCnyDk"
      },
      "source": [
        "**3.0** Run the following code to define a DecisionTreeModel and load the **income** dataset only with the numerical variables. Then, answer the following questions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "G9M3JhlpnyDl",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ae0f57b86252cc38b02cac3d05e08bbf",
          "grade": false,
          "grade_id": "cell-d7f58621bad12aad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34596c13-385e-47ee-d297-4ced955f305f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score accuracy: 0.851\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "columns = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
        "data = pd.read_csv('income.csv',usecols=columns)\n",
        "data_test = pd.read_csv('income_test.csv',usecols=columns)\n",
        "# Convert target variable to 0 and 1\n",
        "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "# Create X and y\n",
        "X_train = data.drop([\"income\"],axis=1)\n",
        "y_train = data['income'].values\n",
        "X_test = data_test.drop([\"income\"],axis=1)\n",
        "y_test = data_test['income'].values\n",
        "# Classifier\n",
        "classifier = DecisionTreeClassifier(min_samples_leaf=4)\n",
        "classifier.fit(X_train,y_train)\n",
        "accuracy_score = accuracy_score(y_test,y_predict)\n",
        "print(\"Model score accuracy: %.3f\" % accuracy_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Yal5vVVInyDo",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c3981752b539236e99415ab6e2cbea1f",
          "grade": false,
          "grade_id": "cell-9b18d6c4e381a9f5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.1** Evaluate the classifier using at least three evaluation metrics except accuracy_score and f1 (weighted)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "id": "4HaPGUuUnyDo",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "12b88026c150b617074a5c06fea36b73",
          "grade": true,
          "grade_id": "cell-905e7dceeb4172c3",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, average_precision_score, f1_score\n",
        "y_predict = classifier.predict(X_test)\n",
        "\n",
        "# BEGIN CODE HERE\n",
        "metric1 = balanced_accuracy_score(y_test, y_predict) \n",
        "metric2 = average_precision_score(y_test, y_predict) \n",
        "metric3 = f1_score(y_test, y_predict, average='micro') \n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "H03BYlAC6B5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff8c93c-d455-4cc7-ad43-2fe2023a3053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score Metric 1: 0.687\n",
            "Model score Metric 2: 0.413\n",
            "Model score Metric 3: 0.790\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Metric 1: %.3f\" % metric1)\n",
        "print(\"Model score Metric 2: %.3f\" % metric2)\n",
        "print(\"Model score Metric 3: %.3f\" % metric3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "YJxhaPxdnyDr",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "361d4753f3c8491a34ff55b6fa3a49b5",
          "grade": false,
          "grade_id": "cell-1f23f3e27600f019",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.2** Do you notice any problems with the classifier? If so, what can you do to change this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "PIEyNQJsnyDt",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "baff993106fd2b655fd47d05c75ea4ce",
          "grade": true,
          "grade_id": "cell-d60d7e6175d184e9",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "The evaluation metrics make the model less accurate in its predictions than before. This is due to the fact that we take into account only the numeric columns in the data set. We could try using the OneHotEncoder to include categorical values as well or using grid search in order to find the best parameters for our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WCN7E_ctnyDu",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "747645b33cb4f5c14796504fac6bf3ce",
          "grade": false,
          "grade_id": "cell-89715acd6c51b332",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.3** Implement your solution using the cells below. Report your results and the process you followed. You are reccommended to use stratification and grid search. You should only have to increase a little bit the metrics you calculated above, and also reach an accuracy score higher than 82%!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "id": "g9Wzx0bknyDv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ccd1d12620f1a3e1c7b026b862056546",
          "grade": true,
          "grade_id": "cell-f44811f1e99ee41e",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e69373-1e23-4eb9-8858-c604952bf99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params:\n",
            "{'classifier__criterion': 'gini', 'classifier__max_depth': 7, 'classifier__max_features': 0.75, 'classifier__min_samples_leaf': 10, 'preprocessor__numeric__imputer__strategy': 'mean'}\n"
          ]
        }
      ],
      "source": [
        "# BEGIN CODE HERE\n",
        "final_score = \"\"\n",
        "#imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "\n",
        "RANDOM_VARIABLE = 42\n",
        "# Load Data\n",
        "columns = ['age','fnlwgt','education_num','hours-per-week','capital-loss','capital-gain','income']\n",
        "data = pd.read_csv('income.csv',usecols=columns)\n",
        "data_test = pd.read_csv('income_test.csv',usecols=columns)\n",
        "# Convert target variable to 0 and 1\n",
        "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "# Create X and y\n",
        "X_train = data.drop([\"income\"],axis=1)\n",
        "y_train = data['income'].values\n",
        "X_test = data_test.drop([\"income\"],axis=1)\n",
        "y_test = data_test['income'].values\n",
        "\n",
        "#numeric_features = ['age','fnlwgt','education_num','capital-gain','capital-loss','hours-per-week']\n",
        "numeric_features = X_train.columns\n",
        "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[('numeric',numeric_transformer, numeric_features)])\n",
        "\n",
        "classifier = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', DecisionTreeClassifier(random_state=RANDOM_VARIABLE))]) #gini is the default criterion\n",
        "classifier.fit(X_train,y_train)\n",
        "y_predict = classifier.predict(X_test)\n",
        "param_grid = {\n",
        "    \"preprocessor__numeric__imputer__strategy\": [\"mean\",\"median\",\"most_frequent\"],\n",
        "    \"classifier__max_depth\": [2, 5, 7, 10],\n",
        "    \"classifier__criterion\": [\"gini\",\"entropy\"],\n",
        "    \"classifier__max_features\": [0.25, 0.5, 0.75, None],\n",
        "    \"classifier__min_samples_leaf\": [1,10,20,30,40,50],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "y_predict =  grid_search.predict(X_test)\n",
        "\n",
        "print(\"Best params:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "accuracy_score = accuracy_score(y_test,y_predict)\n",
        "metric1 = balanced_accuracy_score(y_test, y_predict) \n",
        "metric2 = average_precision_score(y_test, y_predict) \n",
        "metric3 = f1_score(y_test, y_predict, average='micro') \n",
        "\n",
        "\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HoDBPL6n6LLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c8bf54-f409-4f64-c9c1-6a676774bad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score accuracy: 0.825\n",
            "Model score Metric 1: 0.697\n",
            "Model score Metric 2: 0.467\n",
            "Model score Metric 3: 0.825\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score accuracy: %.3f\" % accuracy_score)\n",
        "print(\"Model score Metric 1: %.3f\" % metric1)\n",
        "print(\"Model score Metric 2: %.3f\" % metric2)\n",
        "print(\"Model score Metric 3: %.3f\" % metric3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "ZyG7hhbFnyDx",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b26041c1723d2858ad0833f8985801db",
          "grade": true,
          "grade_id": "cell-c99ca88f33f3717c",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "The process followed was:\n",
        "- The data were loaded. The X_train and X_test data include only the numeric columns(except from the 'income' one). The y_train and y_test consist only of the 'income' column.\n",
        "- The \"<=50K\" and \">50K\" values of y sets were mapped to \"0\" and \"1\" for each example.\n",
        "-  A \"preprocessor\" (with a SimpleImputer) with the numeric transformation and the numeric features was made. A pipeline was used for the X_train and y_train data.\n",
        "- The grid search parameters were the same as Exercise 2. \n",
        "- Then, a 5-fold cross-validation is used, which may not be the best one(10-fold may be better), but it is a quick and generally accurate one.\n",
        "- The scores of accuracy, balanced accuracy, average precision and f1 micro were calculated.\n",
        "\n",
        "The results are: \n",
        "- score of accuracy: 82.5%\n",
        "- score of balanced accuracy: 69.7%\n",
        "- score of average precision : 46.7%\n",
        "- score of fmicro: 82.5%\n",
        "\n",
        "The best parameters, according to Grid Search are:\n",
        "- 'gini' for the criterion\n",
        "-  7 for max_depth \n",
        "-  0.75 for max_features\n",
        "-  10 for min_samples_leaf and\n",
        "- 'mean' for the numeric imputer strategy\n",
        "\n",
        "\n",
        "The scores are indeed a little higher now that we found better parameters with grid search. The accuracy is higher than 82% as expected."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}